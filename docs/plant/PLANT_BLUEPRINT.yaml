# PLANT BLUEPRINT - Golden Source
# Plant Phase: Production Systems Implementation
# Version: 1.0
# Owner: Systems Architect Agent
# Created: 2026-01-14
# Purpose: Single source of truth for Plant design, development, and maintenance phases
# Constitutional Alignment: L0/L1 from first moment, agent-maintained platform mindset

---

## BLUEPRINT METADATA
blueprint:
  name: "PLANT_BLUEPRINT"
  phase: "Plant (Production Certification & Governance)"
  status: "Active - Implementation Ready"
  coverage_target: "90%+ of Plant development"
  validation_method: "Agent self-validation via simulated journeys (PP/CP integration)"
  approach: "Bottom-up (BaseEntity → Entities → Infrastructure → Orchestration)"
  cost_mindset: "Disruptive + Low-Cost (agent-maintained, not ops-patched)"
  
---

## SECTION 1: ENTITY & DATA MODEL
# Foundation: BaseEntity pattern is universal root for all entities
# Reference: /main/Foundation/template/base_entity.yml
# Key Principle: All entities (Agent, Skill, JobRole, Team, Industry) inherit from BaseEntity

entities:
  
  # FOUNDATIONAL INHERITANCE
  base_entity:
    name: "BaseEntity"
    purpose: "Universal root class for all Plant entities"
    reference: "/main/Foundation/template/base_entity.yml"
    sections:
      - "identity (uuid, entity_type, external_id)"
      - "lifecycle (created_at, updated_at, deleted_at, status)"
      - "versioning (version_hash, amendment_history, evolution_markers)"
      - "constitutional_alignment (l0_compliance_status, amendment_alignment, drift_detector)"
      - "audit_trail (append_only, hash_chain_sha256, tamper_proof)"
      - "metadata (tags, custom_attributes, governance_notes)"
      - "relationships (parent_id, child_ids, governance_agent_id)"
    
    implementation_checklist:
      - "[ ] Python dataclass with Pydantic v2 validation"
      - "[ ] PostgreSQL base table with RLS policies"
      - "[ ] Hash chain methods for audit trail"
      - "[ ] Constitutional alignment validators"
      - "[ ] Versioning methods (breaking vs non-breaking)"
  
  # ENTITY DEPENDENCY GRAPH
  dependency_graph:
    description: "Plant entity inheritance and relationships"
    layers:
      - layer: "Layer 0 - Root"
        entities:
          - "BaseEntity (universal root)"
      
      - layer: "Layer 1 - Fundamental Concepts"
        entities:
          - "Skill (inherits from BaseEntity)"
          - "JobRole (inherits from BaseEntity)"
        relationships:
          - "Skill can appear in multiple JobRoles"
      
      - layer: "Layer 2 - Composition"
        entities:
          - "Team (inherits from BaseEntity)"
        relationships:
          - "Team contains multiple Agents"
          - "Team requires at least 1 JobRole"
          - "Team.skills = union of Agent.skills"
      
      - layer: "Layer 3 - Agent Representation"
        entities:
          - "Agent (inherits from BaseEntity)"
        relationships:
          - "Agent has unique Skill + JobRole + Team combination"
          - "Agent has Industry specialization"
      
      - layer: "Layer 4 - Market Segmentation"
        entities:
          - "Industry (inherits from BaseEntity)"
        relationships:
          - "Industry has 1..N Agents"
          - "Industry embeddings (pgvector-384 via MiniLM)"
    
    validation_rules:
      - "All entities must pass BaseEntity compliance check"
      - "No circular parent-child relationships allowed"
      - "Skill + JobRole + Team combination must be unique per Agent"
      - "Industry specialization locked after Agent birth (non-breaking evolution)"
  
  # PLANT-SPECIFIC ENTITIES
  skill:
    definition: "Capability instance that Agents and JobRoles possess"
    inherits_from: "BaseEntity"
    postgres_table: "skill_entity"
    key_attributes:
      - "name (string, unique)"
      - "description (text)"
      - "category (marketing, education, sales)"
      - "embedding_384 (pgvector-384, MiniLM-generated)"
      - "constitutional_alignment (L0/L1 check)"
      - "genesis_certification (certification_id, date, hash)"
    
    implementation_priority: 1
    estimated_effort: "2 days (Python class + migrations + tests)"
  
  job_role:
    definition: "Collection of required Skills for a specific role"
    inherits_from: "BaseEntity"
    postgres_table: "job_role_entity"
    key_attributes:
      - "name (string, unique)"
      - "description (text)"
      - "required_skills (array of skill_ids)"
      - "seniority_level (junior, mid, senior)"
      - "industry (reference to Industry)"
      - "genesis_certification (batch certified)"
    
    implementation_priority: 2
    estimated_effort: "2 days"
  
  team:
    definition: "Collection of Agents with unified Skill + JobRole"
    inherits_from: "BaseEntity"
    postgres_table: "team_entity"
    key_attributes:
      - "name (string, unique)"
      - "description (text)"
      - "agents (array of agent_ids)"
      - "skills (computed from union of agents)"
      - "job_role (single JobRole reference)"
      - "industry (reference to Industry)"
      - "performance_metrics (retention, response_time)"
    
    implementation_priority: 3
    estimated_effort: "3 days (includes computed fields)"
  
  agent:
    definition: "Individual AI workforce member with Skill + JobRole + Team"
    inherits_from: "BaseEntity"
    postgres_table: "agent_entity"
    key_attributes:
      - "name (string, unique)"
      - "skill_id (single skill reference)"
      - "job_role_id (single job_role reference)"
      - "team_id (single team reference)"
      - "industry_id (single industry reference, locked after birth)"
      - "agent_dna_eeprom (5 persistent files: plan.md, errors.jsonl, precedents.json, constitution_snapshot, audit_log.jsonl)"
      - "genesis_certification (certification_id, date, hash, 42-point checklist)"
      - "precedent_seeds (array of seed_ids)"
      - "performance_metrics (98% retention, 2hr response time, etc.)"
    
    implementation_priority: 4
    estimated_effort: "4 days (most complex entity)"
  
  industry:
    definition: "Market segment with 1..N Agents specialization"
    inherits_from: "BaseEntity"
    postgres_table: "industry_entity"
    key_attributes:
      - "name (string, unique: marketing, education, sales)"
      - "description (text)"
      - "embedding_384 (pgvector-384, computed from agent embeddings)"
      - "agents_count (computed count)"
      - "performance_metrics (aggregated from agents)"
    
    implementation_priority: 5
    estimated_effort: "2 days (mostly computed fields)"

---

## SECTION 2: INFRASTRUCTURE COMPONENTS
# Reference: /main/Foundation/architecture_manifest.yml
# Reference: /main/Foundation/TOOLING_SELECTION_DECISION.md
# Key Principle: Minimal viable infrastructure, agent-maintained operational model

infrastructure:
  
  # CORE PLANT SERVICES (Extensions to CP/PP architecture)
  plant_specific_services:
    
    genesis_webhook:
      name: "Genesis Webhook (Port 9001)"
      purpose: "Production certification service - L0/L1 compliance gate"
      type: "FastAPI microservice"
      deployment: "GCP Cloud Run"
      resources:
        cpu: "2 vCPU"
        memory: "1 GB"
        instances: "1-3 (stateless, auto-scale)"
      
      endpoints:
        - "POST /certify/skill - Validate and certify individual Skill"
        - "POST /certify/job - Validate and certify individual JobRole"
        - "POST /validate/agent - Run 42-point Agent certification checklist"
        - "POST /precedents/supersede - Apply precedent seed, manage supersession"
        - "POST /certify/batch - Batch certify 1..50 entities (L0 per-entity validation)"
      
      dependencies:
        - "PostgreSQL (precedent_seeds table, audit_logs table)"
        - "Pub/Sub (certification results topic)"
        - "Redis (certification cache, TTL 24h)"
        - "ML Inference (8005 - embeddings verification)"
      
      constitutional_role: "Genesis Authority - immutable certification gate"
      reference: "/main/Foundation/architecture_decision_records.md (ADR-007)"
    
    constitutional_query_api:
      name: "Constitutional Query API (Port 8004 extension)"
      purpose: "Vector search + precedent seed retrieval"
      type: "FastAPI microservice extension to Customer Service (8004)"
      endpoints:
        - "POST /query/precedents - Semantic search precedent seeds (cosine similarity >0.9)"
        - "GET /precedents/{seed_id} - Retrieve precedent seed + supersession chain"
        - "GET /query/constitution - Fetch current L0/L1 snapshot with hash"
      
      dependencies:
        - "PostgreSQL (precedent_seeds table with pgvector-384)"
        - "Weaviate Vector DB (semantic search, MiniLM embeddings)"
        - "Redis (query cache)"
  
  # DATA LAYER
  data_layer:
    
    # ENVIRONMENT STRATEGY (4 environments)
    environments:
      description: "Multi-environment deployment strategy with separate databases"
      total_environments: 4
      
      local_codespace:
        name: "Local / Codespace"
        purpose: "Developer workstations, GitHub Codespaces"
        database: "Docker PostgreSQL container (localhost:5432)"
        database_name: "plant_local"
        deployment: "Docker Compose (local dev stack)"
        config_file: ".env.local"
        characteristics:
          - "Relaxed SLAs (validate_self <50ms vs <10ms prod)"
          - "RSA-2048 (faster testing vs RSA-4096 prod)"
          - "Debug logging enabled"
          - "Redis TTL 1 hour (faster iteration)"
        cost: "$0 (developer laptops, Codespaces free tier)"
      
      demo_gcp:
        name: "Demo (GCP Cloud Run)"
        purpose: "Customer demos, POCs, short-lived showcase data"
        deployment: "Cloud Run (auto-scale 0-3 instances)"
        config_file: ".env.demo"
        characteristics:
          - "Production-like SLAs"
          - "RSA-4096 from Secret Manager"
          - "CORS: https://demo.waooaw.dev"
          - "Data retention: 7 days (auto-purge old demos)"
        
        database_strategy_committed:
          name: "Committed Instance (Always-On)"
          database: "Cloud SQL PostgreSQL (demo instance, db-f1-micro)"
          database_name: "plant_demo"
          connection: "Unix socket /cloudsql/PROJECT:REGION:plant-demo"
          cost: "$20-30/month"
          pros:
            - "Instant startup (no cold start latency)"
            - "Predictable performance"
            - "Straightforward scaling"
          cons:
            - "Fixed cost regardless of usage"
            - "Not ideal for demo-only usage patterns"
        
        database_strategy_serverless:
          name: "Serverless (Pay-Per-Use) - RECOMMENDED"
          database: "Cloud SQL Serverless PostgreSQL (demo instance)"
          database_name: "plant_demo"
          connection: "Unix socket /cloudsql/PROJECT:REGION:plant-demo-serverless"
          auto_scaling: "0.5 → 4 vCPU (auto-managed)"
          auto_pause: "15 minutes inactivity → paused"
          cost: "$2-5/month (for typical demo usage pattern: 2 hrs/day)"
          pros:
            - "Massive cost savings (~80-90% reduction)"
            - "Scales to zero when idle"
            - "Pay only for what you use"
            - "Perfect for episodic demo runs"
          cons:
            - "~30 second cold start on first request after pause"
            - "Acceptable for demo workload"
          startup_latency_acceptable: "Yes (demos typically 5+ min duration)"
        
        recommendation: "Use Serverless for demo environment (lower cost, acceptable latency)"
      
      uat_gcp:
        name: "UAT (GCP Cloud Run)"
        purpose: "Pre-production testing, QA validation, performance benchmarks"
        deployment: "Cloud Run (auto-scale 1-5 instances)"
        config_file: ".env.uat"
        characteristics:
          - "Strict production SLAs enforced"
          - "Performance benchmarks enabled"
          - "Full observability (Prometheus, Cloud Trace, Profiler)"
          - "Staging data (anonymized production-like datasets)"
        
        database_strategy_committed:
          name: "Committed Instance (Always-On)"
          database: "Cloud SQL PostgreSQL (uat instance, db-g1-small)"
          database_name: "plant_uat"
          connection: "Unix socket /cloudsql/PROJECT:REGION:plant-uat"
          cost: "$30-40/month"
          pros:
            - "Instant startup (no latency)"
            - "Consistent benchmark results"
            - "Suitable for frequent test runs"
          cons:
            - "Fixed cost for intermittent usage"
        
        database_strategy_serverless:
          name: "Serverless (Pay-Per-Use) - RECOMMENDED"
          database: "Cloud SQL Serverless PostgreSQL (uat instance)"
          database_name: "plant_uat"
          connection: "Unix socket /cloudsql/PROJECT:REGION:plant-uat-serverless"
          auto_scaling: "0.5 → 4 vCPU (auto-managed)"
          auto_pause: "15 minutes inactivity → paused"
          cost: "$5-10/month (for typical UAT usage pattern: 4 hrs/day)"
          pros:
            - "Cost savings (~70-75% reduction)"
            - "Scales automatically during peak test runs"
            - "Pauses during off-hours/weekends"
            - "Pay only for test execution time"
          cons:
            - "~30 second cold start post-pause"
            - "Minor impact on benchmark consistency (acceptable)"
          benchmark_impact: "Negligible (pre-warm connections, benchmark tests are typically 5+ min duration)"
        
        recommendation: "Use Serverless for UAT environment (cost-effective, benchmark-friendly)"
      
      prod_gcp:
        name: "Production (GCP Cloud Run)"
        purpose: "Live customer-facing workloads"
        deployment: "Cloud Run (auto-scale 2-10 instances, min 2 for HA)"
        config_file: ".env.prod"
        characteristics:
          - "Strict SLAs (validate_self <10ms, pgvector <500ms)"
          - "RSA-4096 with quarterly rotation"
          - "Point-in-time recovery enabled"
          - "Daily backups (30-day retention)"
          - "Rate limiting (1000 req/min per customer)"
          - "Cost alerts at $100/month threshold"
        
        database_strategy_committed_ha:
          name: "Committed HA Instance (Always-On, High Availability)"
          database: "Cloud SQL PostgreSQL with HA (prod instance, db-n1-standard-1)"
          database_name: "plant_prod"
          connection: "Unix socket /cloudsql/PROJECT:REGION:plant-prod"
          configuration: "Primary + standby replica, auto-failover"
          backups: "Automated daily + point-in-time recovery (30-day retention)"
          cost: "$50-80/month (includes HA premium, backup storage)"
          
          sla_guarantees:
            - "99.95% uptime SLA (customer-facing)"
            - "RTO (Recovery Time Objective): <5 minutes"
            - "RPO (Recovery Point Objective): <5 minutes"
            - "Latency SLA: <10ms for validate_self"
          
          why_no_serverless_for_prod:
            - "Serverless auto-pauses after inactivity → violates customer SLA"
            - "30 second cold start is unacceptable for customer requests"
            - "HA failover logic incompatible with serverless pause behavior"
            - "Production workloads require guaranteed capacity"
            - "Predictable costs more important than marginal savings"
          
          cost_justification:
            - "HA redundancy cost ($15-20/mo premium) justified by 99.95% SLA"
            - "Daily backups cost ($5-10/mo) justified by data criticality"
            - "Committed capacity cost ($30-40/mo) justified by customer guarantees"
            - "Total: $50-80/mo for enterprise-grade production database"
        
        recommendation: "Use Committed HA Instance for production (mandatory for customer SLA)"
      
      cost_strategy_summary:
        description: "Recommended database strategy for cost optimization"
        total_monthly_cost: "$57-95/month (serverless non-prod, committed HA prod)"
        cost_breakdown:
          - "Local: $0 (Docker PostgreSQL)"
          - "Demo: $2-5/month (Cloud SQL Serverless)"
          - "UAT: $5-10/month (Cloud SQL Serverless)"
          - "Prod: $50-80/month (Cloud SQL HA Committed)"
        
        cost_comparison_table:
          headers: ["Environment", "All-Committed Strategy", "Recommended Strategy", "Savings"]
          rows:
            - ["Local", "$0", "$0", "$0"]
            - ["Demo", "$20-30/mo", "$2-5/mo", "$15-28/mo"]
            - ["UAT", "$30-40/mo", "$5-10/mo", "$20-35/mo"]
            - ["Prod", "$50-80/mo", "$50-80/mo", "$0"]
            - ["TOTAL", "$100-150/mo", "$57-95/mo", "$35-55/mo (~50% savings)"]
        
        recommendation:
          strategy: "Baseline to Serverless Non-Prod + Committed HA Prod (from Day 1)"
          rationale:
            - "Environment management identical: Cloud SQL Proxy works same way (Unix socket)"
            - "Alembic migrations, CICD workflow, config management unchanged"
            - "No phase-in complexity: one decision, one execution"
            - "50% cost reduction achieved immediately (no wasted committed months)"
            - "Serverless is GA, production-ready, widely deployed at scale"
            - "Demo/UAT intermittent usage patterns: serverless auto-pause perfect fit"
            - "Aligns with 'disruptive + low-cost' PLANT philosophy"
          
          implementation_approach:
            - "Sprint 1: Deploy all 4 environments with this strategy from day 1"
            - "Demo: Cloud SQL Serverless (0.5-4 vCPU, auto-pause after 15 min)"
            - "UAT: Cloud SQL Serverless (0.5-4 vCPU, auto-pause after 15 min)"
            - "Prod: Cloud SQL HA Committed (db-n1-standard-1 + standby, always-on)"
            - "Local: Docker PostgreSQL (no GCP cost)"
            - "No future migration work needed"
      
      migration_strategy:
        description: "Database schema evolution across 4 environments"
        tool: "Alembic (SQLAlchemy migrations)"
        approach: "CI/CD automated migrations via GitHub Actions"
        
        workflow:
          - "1. Developer creates migration: alembic revision -m 'add_skill_category'"
          - "2. Test locally: ./scripts/migrate-db.sh local"
          - "3. Commit to branch: git commit -m 'feat(plant): add skill category'"
          - "4. Push triggers CI: GitHub Actions runs migrations on demo"
          - "5. Manual trigger UAT: Workflow dispatch with environment=uat"
          - "6. Manual trigger PROD: Workflow dispatch with environment=prod (requires approval)"
        
        safety_mechanisms:
          - "Production backup before migration (gcloud sql backups create)"
          - "Smoke tests post-migration (pytest integration tests)"
          - "Rollback capability (alembic downgrade -1)"
          - "Migration log audit trail (database/migrations/migration_log.txt)"
        
        github_actions_workflow: ".github/workflows/plant-db-migrations.yml"
        scripts:
          - "scripts/migrate-db.sh <environment>"
          - "scripts/seed-db.sh <environment>"
        
        cicd_secrets_required:
          - "GCP_SA_KEY_DEMO (service account for demo)"
          - "GCP_SA_KEY_UAT (service account for uat)"
          - "GCP_SA_KEY_PROD (service account for prod)"
          - "DATABASE_URL_DEMO, DATABASE_URL_UAT, DATABASE_URL_PROD"
          - "CLOUD_SQL_CONNECTION_NAME_DEMO, CLOUD_SQL_CONNECTION_NAME_UAT, CLOUD_SQL_CONNECTION_NAME_PROD"
    
    # DATABASE CONNECTOR (Global DB Abstraction Layer)
    database_connector:
      name: "Database Connector (Global SQLAlchemy Session Manager)"
      purpose: "Single entry point for all database operations with connection pooling"
      architecture: "Async-first, environment-aware, FastAPI-integrated"
      reference: "src/Plant/BackEnd/core/database.py (reference implementation)"
      
      pattern: "Global Connector Pattern with Dependency Injection"
      
      key_features:
        - "Environment detection: Reads .env to pick local/demo/uat/prod database URL"
        - "Connection pooling: Async SQLAlchemy with configurable pool size per environment"
        - "Cloud SQL Proxy integration: Unix socket support (/cloudsql/PROJECT:REGION:instance)"
        - "Async-first: Uses asyncpg driver (non-blocking I/O for FastAPI)"
        - "Session factory: Per-request session lifecycle management (FastAPI Depends)"
        - "Extension auto-loading: pgvector, uuid-ossp loaded on connection"
        - "Error handling: Retry logic, circuit breaker, graceful degradation"
        - "Observability: Metrics emission (active connections, query latency, pool exhaustion)"
      
      connection_pool_strategy:
        local_codespace:
          pool_size: 5
          max_overflow: 10
          rationale: "Developer workstation, low concurrency"
        
        demo_gcp_serverless:
          pool_size: 1
          max_overflow: 10
          rationale: "Cloud Run max concurrent requests = 1 default, serverless scaling"
          cloud_sql_proxy: "Unix socket via /cloudsql/PROJECT:REGION:plant-demo"
        
        uat_gcp_serverless:
          pool_size: 1
          max_overflow: 15
          rationale: "Auto-scale 1-5 instances, allow overflow for peak load"
          cloud_sql_proxy: "Unix socket via /cloudsql/PROJECT:REGION:plant-uat"
        
        prod_gcp_ha:
          pool_size: 5
          max_overflow: 20
          rationale: "HA mode, guaranteed capacity, customer requests"
          cloud_sql_proxy: "Unix socket via /cloudsql/PROJECT:REGION:plant-prod"
          connection_timeout: 30
          statement_timeout: 60000  # 60 seconds
      
      implementation_details:
        engine_creation: |
          create_async_engine(
              database_url,
              poolclass=AsyncQueuePool,
              pool_size=settings.database_pool_size,
              max_overflow=settings.database_max_overflow,
              connect_args={"connect_timeout": 10, "command_timeout": 30},
              echo=settings.database_echo,
          )
        
        session_factory: |
          async_sessionmaker(
              engine,
              class_=AsyncSession,
              expire_on_commit=False,
              autocommit=False,
              autoflush=False,
          )
        
        dependency_injection: |
          @app.get("/items/")
          async def read_items(db: AsyncSession = Depends(get_db_session)):
              result = await db.execute(select(Item))
              return result.scalars().all()
      
      environment_variables_required:
        - "DATABASE_URL (or auto-constructed from DB_HOST, DB_PORT, DB_NAME, DB_USER, DB_PASSWORD)"
        - "DATABASE_POOL_SIZE (optional, defaults from environment config)"
        - "DATABASE_ECHO (optional, true for SQL logging in dev)"
        - "CLOUD_SQL_CONNECTION_NAME (for Cloud Run: PROJECT:REGION:instance)"
      
      error_handling:
        connection_pool_exhaustion: "Circuit breaker + retry with exponential backoff"
        database_unreachable: "Health check failure + graceful error response"
        query_timeout: "Statement timeout enforced per environment"
        rls_policy_violation: "Transaction rollback + audit trail append"
      
      observability:
        metrics_emitted:
          - "db_pool_size (current size)"
          - "db_pool_checkedout (active connections)"
          - "db_pool_overflow_created (overflow instances)"
          - "db_query_duration_ms (latency percentiles: p50, p95, p99)"
          - "db_pool_exhaustion_events (circuit breaker triggers)"
        
        logging:
          - "Connection acquire/release (correlation ID attached)"
          - "Query execution (sanitized SQL, parameters masked)"
          - "RLS policy checks (entity ID, user context)"
          - "Migration logs (alembic revision, timestamp, status)"
        
        integration:
          - "Cloud Trace: Request tracing with db_query spans"
          - "Cloud Monitoring: Pool metrics dashboard"
          - "Cloud Logging: Structured logs (JSON)"
      
      testing_support:
        test_database_url: "postgresql+asyncpg://test:test@localhost/plant_test"
        testcontainers_integration: "Automatic PostgreSQL container for pytest"
        fixtures_provided:
          - "async_session_fixture (per-test isolated session)"
          - "test_db_cleanup (auto-rollback after test)"
          - "seed_test_data (factory methods for Skill, Agent, Industry)"
      
      reference_implementation_file: "src/Plant/BackEnd/core/database.py"
      documentation_file: "docs/plant/DATABASE_CONNECTOR_GUIDE.md"
    
    postgresql_cloud_sql:
      name: "PostgreSQL (Cloud SQL Managed)"
      purpose: "Universal data persistence with RLS, append-only audit, pgvector"
      reference: "/main/Foundation/TOOLING_SELECTION_DECISION.md (Database section)"
      
      tier: "db-f1-micro (demo), db-g1-small (uat), db-n1-standard-1 (prod with HA)"
      region: "us-central1 (all environments)"
      
      tables_plant:
        - "base_entity (root inheritance table)"
        - "skill_entity (inherits from base_entity)"
        - "job_role_entity (inherits from base_entity)"
        - "team_entity (inherits from base_entity)"
        - "agent_entity (inherits from base_entity)"
        - "industry_entity (inherits from base_entity)"
        - "precedent_seeds (pgvector-384, JSON content, supersession links)"
        - "audit_logs_plant (append-only, hash-chained, tamper-proof)"
      
      security_policies:
        - "Row-Level Security (RLS) on all tables"
        - "Hash-chain audit logs with SHA-256"
        - "Reference: /main/Foundation/architecture_decision_records.md (ADR-003, ADR-004)"
      
      cost: "$15-25/month (MVP tier)"
    
    weaviate_vector_db:
      name: "Weaviate Vector DB (pgvector-384)"
      purpose: "Semantic search for precedent seeds, industry embeddings"
      embedding_model: "MiniLM (sentence-transformers, CPU-optimized)"
      vector_dimension: 384
      search_threshold: "cosine_similarity > 0.9 (contradiction detection)"
      
      implementation_note: "Can use PostgreSQL pgvector extension instead of separate Weaviate for MVP (cost savings)"
      cost: "$5-10/month (pgvector extension on PostgreSQL)"
    
    redis_cache:
      name: "Redis (Google Cloud Memorystore)"
      purpose: "Certification cache, query cache, model cache (ML Inference)"
      
      cache_patterns:
        - "genesis_cert_{entity_id} → TTL 24h (certification results)"
        - "precedent_query_{hash} → TTL 6h (semantic search results)"
        - "ml_model_cache → embeddings (persistent across requests)"
      
      cost: "$5-10/month"
  
  # MESSAGE BUS & EVENTS
  message_bus:
    
    pub_sub:
      name: "Google Cloud Pub/Sub"
      purpose: "Event-driven async messaging, certification results, audit stream"
      reference: "/main/Foundation/TOOLING_SELECTION_DECISION.md (Message Bus section)"
      
      topics_plant:
        - "genesis_certifications (entity_certified, entity_rejected)"
        - "precedent_seeds_applied (seed_id, agent_id, timestamp)"
        - "audit_events_plant (all constitutional breaches, drift detection)"
      
      subscriptions:
        - "genesis_certifications → Pub/Sub → PP Portal (webhook)"
        - "precedent_seeds_applied → Genesis Webhook (for precedent updates)"
        - "audit_events_plant → Audit Trail Service (hash chain append)"
      
      cost: "$10-15/month (after free tier)"

---

## SECTION 3: ORCHESTRATION & WORKFLOWS
# Reference: /main/Foundation/architecture_decision_records.md (ADR-007: Temporal)
# Key Decision: Temporal Workflow Engine for saga patterns, retry logic, durability
# Plant Folds: Fold 3 (Agent Manufacturing), Fold 4 (Evolution/Governance)

orchestration:
  
  workflow_engine:
    name: "Temporal Workflow Engine"
    status: "Accepted Architecture Decision (ADR-007)"
    purpose: "Orchestrate Plant Fold 3 (manufacturing) and Fold 4 (evolution)"
    deployment: "GCP Cloud Run (port 8001)"
    persistence: "PostgreSQL (temporal_workflows table)"
    
    reference: "/main/Foundation/architecture_decision_records.md#adr-007-temporal-workflow-engine-for-orchestration"
    
    rationale:
      - "Durable execution (workflows survive service restarts)"
      - "Automatic retries with exponential backoff"
      - "Saga patterns for compensation logic (rollback on failure)"
      - "Versioning support (deploy new code without breaking running workflows)"
  
  # FOLD 3: AGENT MANUFACTURING WORKFLOW
  agent_manufacturing_workflow:
    name: "Agent Manufacturing Lifecycle (Fold 3)"
    duration: "30-45 minutes (durable across restarts)"
    stages:
      - "Stage 1: Birth (Agent entity creation, BaseEntity initialization)"
      - "Stage 2: Assembly (OAuth integration, external API connections)"
      - "Stage 3: Certification (Genesis 42-point checklist)"
      - "Stage 4: Activation (agent_status → active, ready for operations)"
    
    temporal_workflow_pseudocode: |
      @workflow.defn
      class AgentManufacturingWorkflow:
          @workflow.run
          async def run(self, agent_id: str):
              # Stage 1: Birth
              await workflow.execute_activity(
                  create_agent_entity,
                  agent_id,
                  retry_policy=RetryPolicy(max_attempts=3)
              )
              
              # Stage 2: Assembly
              try:
                  await workflow.execute_activity(configure_oauth, agent_id)
                  await workflow.execute_activity(validate_integrations, agent_id)
              except AssemblyFailure:
                  await workflow.execute_activity(compensate_assembly, agent_id)
                  raise
              
              # Stage 3: Certification (Genesis gate)
              try:
                  await workflow.execute_activity(genesis_certification, agent_id)
              except CertificationFailure:
                  await workflow.execute_activity(compensate_manufacturing, agent_id)
                  raise
              
              # Stage 4: Activation
              await workflow.execute_activity(activate_agent, agent_id)
              
              return {"agent_id": agent_id, "status": "active"}
    
    error_handling:
      - "Assembly failures → Compensate (cleanup OAuth, close connections)"
      - "Genesis rejection → Compensate (delete agent, notify Governor)"
      - "All failures → Append to audit trail with hash chain"
    
    integration_points:
      - "Genesis Webhook (port 9001) - Stage 3 certification"
      - "Constitutional Query API (port 8004) - Stage 2 OAuth validation"
      - "Pub/Sub (audit_events_plant) - Stage 3 certification result"
  
  # FOLD 4: EVOLUTION & GOVERNANCE WORKFLOW
  evolution_governance_workflow:
    name: "Agent Evolution & Constitutional Alignment (Fold 4)"
    frequency: "Continuous (event-triggered: precedent update, drift detection)"
    
    workflows:
      - name: "Precedent Supersession Workflow"
        trigger: "When new precedent seed validated by Vision Guardian"
        steps:
          - "1. Retrieve agent's current precedent_seeds array"
          - "2. Query /query/precedents (vector search for similar seeds)"
          - "3. If supersession match: apply new seed, mark old as superseded"
          - "4. Update agent_entity.precedent_seeds"
          - "5. Emit audit event (append-only, hash-chained)"
        
        saga_compensation: "If update fails mid-transaction → Revert to previous seed"
      
      - name: "Constitutional Drift Detection Workflow"
        frequency: "Daily (Vision Guardian audit)"
        steps:
          - "1. Calculate L0/L1 constitution hash (snapshot_datetime)"
          - "2. Compare with agents' constitution_snapshot (from agent DNA)"
          - "3. If hash_mismatch: agent_status → under_review"
          - "4. Emit audit event, notify Governor for re-certification"
        
        implementation_note: "Can run async batch job (not real-time, acceptable per journey spec)"

---

## SECTION 4: CONSTITUTIONAL ALIGNMENT
# Key Principle: L0/L1 enforcement at every infrastructure layer
# Reference: /main/Foundation/L0_CONSTITUTION.md, Amendment-001
# Validation: Every design decision traces back to constitutional principle

constitutional_alignment:
  
  # L0 PRINCIPLES MAPPED TO PLANT INFRASTRUCTURE
  l0_enforcement_points:
    
    - principle: "L0-01: Governor Single Source of Truth"
      plant_enforcement:
        - "Genesis Webhook (port 9001) validates Governor role before certification"
        - "All approval workflows route through Governance Service (port 8003)"
        - "Precedent seeds marked with approving_governor_id (audit trail)"
      implementation_location: "Genesis Webhook + Governance Service"
      reference: "/main/Foundation/governor_agent_charter.md"
    
    - principle: "L0-02: Constitutional Amendment Authority"
      plant_enforcement:
        - "Constitutional Query API (port 8004) fetches current L0/L1 snapshot"
        - "Agent DNA (constitution_snapshot file) captures Amendment-001 hash at birth"
        - "Vision Guardian daily audit detects constitution_snapshot hash drift"
      implementation_location: "Agent DNA + Constitutional Query API + Vision Guardian"
    
    - principle: "L0-03: Append-Only Audit Invariant"
      plant_enforcement:
        - "PostgreSQL audit_logs_plant table with INSERT-only triggers"
        - "No UPDATE/DELETE allowed (PostgreSQL RLS + row-level audit)"
        - "SHA-256 hash chain links consecutive audit entries (tamper detection)"
      implementation_location: "PostgreSQL + Audit Service"
      reference: "/main/Foundation/architecture_decision_records.md (ADR-003)"
    
    - principle: "L0-04: Precedent Seed Supersession"
      plant_enforcement:
        - "Precedent seeds never deleted, only marked superseded_by"
        - "Supersession chain preserved in PostgreSQL precedent_seeds table"
        - "Genesis Webhook /precedents/supersede endpoint enforces immutability"
      implementation_location: "Genesis Webhook + PostgreSQL"
    
    - principle: "L0-05: Constitutional Compliance Gate"
      plant_enforcement:
        - "Genesis Webhook is L0 compliance gate (no bypass possible)"
        - "All agents must pass 42-point checklist before activation"
        - "Vision Guardian monitors Genesis availability (alert if DLQ overflow)"
      implementation_location: "Genesis Webhook"
  
  # CONSTITUTIONAL CHECKPOINTS IN PLANT WORKFLOWS
  workflow_constitutional_checkpoints:
    
    - workflow: "Agent Manufacturing (Fold 3)"
      checkpoints:
        - "Stage 1 (Birth): BaseEntity initialization validates L0 compliance markers"
        - "Stage 2 (Assembly): OAuth scope validated against Agent's industry context"
        - "Stage 3 (Certification): Genesis runs 42-point L0/L1 checklist"
        - "Stage 4 (Activation): agent_entity.constitutional_alignment == 'aligned'"
    
    - workflow: "Evolution & Governance (Fold 4)"
      checkpoints:
        - "Precedent Supersession: Vision Guardian pre-validates seed quality vs L0"
        - "Drift Detection: Constitution hash mismatch → agent_status under_review"
        - "Governor Reactivation: Only Governor can move under_review → active"
  
  # GOVERNANCE AGENTS IN PLANT
  governance_agents:
    - name: "Genesis (Certification Authority)"
      role: "L0 Compliance Gate - validates entities before production use"
      port: 9001
      authority: "Immutable, cannot be bypassed"
      reference: "/main/Foundation/genesis_foundational_governance_agent.md"
    
    - name: "Vision Guardian (Constitutional Overseer)"
      role: "Constitutional drift detection, precedent quality audit"
      daily_audit: "L0/L1 hash verification, precedent contradiction detection"
      escalation: "Governor for drift resolution, Systems Architect for infrastructure issues"
      reference: "/main/Foundation/vision_guardian_foundational_governance_agent.md"
    
    - name: "Governor (Human Authority)"
      role: "Final approval authority, constitutional amendment approval"
      plant_involvement: "Re-certification approvals, precedent resolution, Genesis decommission authority"
      reference: "/main/Foundation/governor_agent_charter.md"

---

## SECTION 5: PLANT INTEGRATION WITH CP/PP
# Reference: /docs/CP/CUSTOMER_PORTAL_JOURNEY.md, /docs/PP/PORTAL_USER_JOURNEY.md
# Key Integration Points: Plant serves as certification backbone for CP/PP agent operations

cp_pp_integration:
  
  # HOW PLANT SERVES CP (CUSTOMER PORTAL)
  customer_portal_integration:
    description: "Plant provides certified agents + precedent seeds for CP customer experience"
    
    integration_flows:
      - flow: "Agent Discovery (CP Search)"
        plant_apis:
          - "GET /agents (filters: industry, skill, rating) → plant provides BaseEntity metadata"
          - "GET /agents/{id}/precedents → plant serves Constitutional Query API (port 8004)"
        data_flow: "CP Frontend → PP Gateway (8015) → Plant services (8001, 8004, 8009)"
      
      - flow: "Trial Setup (CP Onboarding)"
        plant_apis:
          - "POST /trials/{trial_id}/agent/{agent_id} → Genesis validates agent certification status"
          - "GET /agents/{agent_id}/constraints (industry, pricing tier) → BaseEntity relationships"
        security: "Trial-mode sandbox routing enforced (ADR-012)"
      
      - flow: "Agent Execution (CP Task)"
        plant_apis:
          - "GET /agents/{agent_id}/precedents (semantic search) → Constitutional Query API"
          - "POST /agents/{agent_id}/execute → Agent Execution Service routes through Governance"
  
  # HOW PLANT SERVES PP (PLATFORM PORTAL)
  platform_portal_integration:
    description: "Plant provides admin visibility + Genesis certification management"
    
    integration_flows:
      - flow: "Health Monitoring (PP Dashboard)"
        plant_apis:
          - "GET /genesis/health (port 9001) → Genesis availability + certification queue depth"
          - "GET /audit/integrity → Hash chain validation status + recent tampering alerts"
        admin_visibility: "PP Portal shows real-time Genesis status + constitutional drift alerts"
      
      - flow: "Certification Management (PP Admin)"
        plant_apis:
          - "POST /agents/batch-certify → Genesis batch certification (max 50)"
          - "GET /audit/logs (genesis_id, timestamp_range) → Audit trail queries"
      
      - flow: "Constitutional Governance (PP Governor)"
        plant_apis:
          - "POST /amendments/approve → Governor approves Amendment-001 supersessions"
          - "POST /precedents/resolve → Governor resolves precedent contradictions"
  
  # SHARED DATA CONTRACTS
  data_contracts:
    reference: "/main/Foundation/contracts/data_contracts.yml"
    
    key_schemas:
      - name: "Agent Certification Result"
        structure:
          - "agent_id (UUID)"
          - "certification_status (approved | rejected | under_review)"
          - "genesis_certification_id (hash)"
          - "timestamp"
          - "approval_scope (industries, pricing_tiers)"
      
      - name: "Precedent Seed"
        structure:
          - "seed_id (UUID)"
          - "content (JSON)"
          - "embedding_384 (pgvector)"
          - "precedent_version (v1 | v2 | etc)"
          - "superseded_by (UUID or null)"
          - "created_at, superseded_at"
      
      - name: "Audit Event (Plant)"
        structure:
          - "event_id (UUID)"
          - "event_type (genesis_certification, precedent_applied, drift_detected)"
          - "agent_id (UUID)"
          - "previous_hash (SHA-256)"
          - "current_hash (SHA-256(previous_hash + event_data))"
          - "timestamp"

---

## SECTION 6: RISK MANAGEMENT & MITIGATION FRAMEWORK
# Key Principle: Identify risks early, design mitigations into infrastructure
# Agent-Maintained Approach: Risks with agent-automatable mitigations (hard stops); rest deferred to judgment

risk_framework:
  
  # CRITICAL RISKS
  critical_risks:
    
    - risk_id: "RISK-PLANT-001"
      title: "Genesis Webhook Single Point of Failure"
      likelihood: "Medium (service crashes, DLQ overflow)"
      impact: "High (agents cannot be certified, manufacturing blocked)"
      
      mitigation:
        strategy: "Hard Stop + Health Monitoring"
        implementation:
          - "Genesis Health Probe (port 9001 /health) checked every 30s by Health Aggregator"
          - "If unavailable >5min: alert Systems Architect, fallback to cache (24h TTL for existing certs)"
          - "No bootstrap allowed without Genesis (no bypass)"
          - "Temporal workflow pauses certification stage, retries with exponential backoff (max 3 days)"
        responsibility: "Systems Architect (restart Genesis), Vision Guardian (constitutional impact)"
      
      acceptance_criteria:
        - "[ ] Genesis availability monitored via Cloud Run health checks"
        - "[ ] Alert routing to Systems Architect + Vision Guardian"
        - "[ ] Fallback cache strategy documented + tested"
    
    - risk_id: "RISK-PLANT-002"
      title: "Constitutional Drift Undetected"
      likelihood: "Medium (daily audit may miss amendments)"
      impact: "Critical (agents operate with outdated L0/L1, constitutional breach)"
      
      mitigation:
        strategy: "Vision Guardian Daily Audit + Rapid Response"
        implementation:
          - "Vision Guardian runs daily hash verification (amendment_001 hash)"
          - "If mismatch detected: suspend agents (status → under_review), notify Governor"
          - "Governor must re-certify agents before reactivation (approval-based, not automatic)"
          - "Audit log records all drift events (non-repudiation)"
        responsibility: "Vision Guardian (detection), Governor (reactivation)"
      
      acceptance_criteria:
        - "[ ] Constitutional drift detection runs daily (cron job)"
        - "[ ] Agent suspension is automatic (no manual delay)"
        - "[ ] Governor approval required before reactivation"
        - "[ ] All drift events logged to audit trail"
    
    - risk_id: "RISK-PLANT-003"
      title: "Precedent Seed Contradiction (Two seeds advice opposite actions)"
      likelihood: "Low (vector similarity >0.9 screening)"
      impact: "High (agent confusion, incorrect decisions)"
      
      mitigation:
        strategy: "Soft Decision (Vision Guardian + Governor Resolution)"
        implementation:
          - "Constitutional Query API (port 8004) checks cosine_similarity >0.9 for potential contradictions"
          - "If contradiction detected: precedent application blocked, escalates to Vision Guardian"
          - "Vision Guardian audits seed quality + approves resolution strategy"
          - "Governor has final say on which seed supersedes the other"
        responsibility: "Vision Guardian (quality audit), Governor (final resolution)"
      
      acceptance_criteria:
        - "[ ] Vector search detects similarity >0.9"
        - "[ ] Escalation to Vision Guardian is automatic"
        - "[ ] Governor can only approve AFTER Vision Guardian review"
  
  # HIGH-PRIORITY RISKS
  high_priority_risks:
    
    - risk_id: "RISK-PLANT-004"
      title: "Audit Trail Tamper Attempt (Hash chain corruption)"
      likelihood: "Low (requires direct DB access)"
      impact: "High (loss of non-repudiation)"
      
      mitigation:
        strategy: "Detection + Alert (daily integrity verification)"
        implementation:
          - "Background job: daily audit trail integrity check (verify hash chain continuity)"
          - "If tamper detected: immediate alert + immutable evidence collection"
          - "Integrity mismatch recorded in separate tamper_alerts table (also append-only)"
        responsibility: "Systems Architect (alert investigation), Audit Service (verification)"
      
      acceptance_criteria:
        - "[ ] Hash chain validation runs daily"
        - "[ ] Tamper events logged to immutable tamper_alerts table"
        - "[ ] Alert delivery to Systems Architect + Governor"
    
    - risk_id: "RISK-PLANT-005"
      title: "Vector DB Cold Start Latency (>500ms first query)"
      likelihood: "Medium (pgvector warm-up or Weaviate restart)"
      impact: "Medium (slow agent discovery, poor UX)"
      
      mitigation:
        strategy: "Soft Decision (monitoring + cache pre-warming)"
        implementation:
          - "Redis caching for frequent queries (TTL 6h)"
          - "Health check includes latency measurement (alert if >300ms)"
          - "Seed data pre-loaded on startup (warm-up embeddings)"
        responsibility: "Systems Architect (infrastructure tuning)"
      
      acceptance_criteria:
        - "[ ] Query cache in place (Redis)"
        - "[ ] Latency monitoring enabled"
        - "[ ] Startup pre-warming procedure documented"
  
  # MEDIUM-PRIORITY RISKS
  medium_priority_risks:
    
    - risk_id: "RISK-PLANT-006"
      title: "DLQ Overflow (Pub/Sub dead-letter queue fills up)"
      likelihood: "Low (with proper retry logic)"
      impact: "Medium (events lost, Genesis certification backlog)"
      
      mitigation:
        strategy: "Hard Stop (alert + manual intervention)"
        implementation:
          - "Health Aggregator monitors DLQ depth (alert at >1000 messages)"
          - "Systems Architect drains DLQ (replay or discard based on event age)"
          - "Post-incident: adjust service SLOs"
        responsibility: "Systems Architect (DLQ management)"
    
    - risk_id: "RISK-PLANT-007"
      title: "Agent DNA File Corruption (one of 5 EEPROM files lost)"
      likelihood: "Low (with PostgreSQL backups)"
      impact: "High (agent loses execution history, precedents, errors log)"
      
      mitigation:
        strategy: "Detection + Recovery (daily backup check)"
        implementation:
          - "Daily verification: read all 5 agent DNA files, checksum validation"
          - "If corruption detected: restore from PostgreSQL JSONB backup"
          - "Alert Systems Architect for root cause investigation"
        responsibility: "Systems Architect (backup management + recovery)"
    
    - risk_id: "RISK-PLANT-008"
      title: "PostgreSQL RLS Policy Bug (customer data leak)"
      likelihood: "Low (with test coverage)"
      impact: "Critical (GDPR violation, customer breach)"
      
      mitigation:
        strategy: "Hard Stop (aggressive testing + audit)"
        implementation:
          - "Unit test every RLS policy (100% coverage)"
          - "Integration tests: cross-customer query attempts blocked"
          - "Audit log all RLS policy violations (suspicious access)"
          - "Monthly compliance review of RLS policies"
        responsibility: "Development Team (test coverage), Audit Service (monitoring)"

---

## SECTION 7: IMPLEMENTATION ROADMAP & VALIDATION
# 90%+ Coverage Delivery via Staged Implementation + Agent Self-Validation

implementation_roadmap:
  
  phase_0_setup:
    name: "Foundations (Week 1)"
    tasks:
      - "[ ] BaseEntity Python class (Pydantic v2 + tests)"
      - "[ ] PostgreSQL schema (base_entity + RLS policies)"
      - "[ ] Hash chain utilities (SHA-256 + verification)"
    
    validation:
      - "Agent self-validates: all BaseEntity methods work"
      - "Simulate: create 5 test entities, verify inheritance + audit trail"
  
  phase_1_entities:
    name: "Core Entities (Week 2-3)"
    tasks:
      - "[ ] Skill entity (Python class + table)"
      - "[ ] JobRole entity"
      - "[ ] Team entity"
      - "[ ] Agent entity (most complex)"
      - "[ ] Industry entity"
    
    validation:
      - "Agent self-validates: entity dependency graph correct"
      - "Simulate: create agent with all relationships, verify constraints"
  
  phase_2_genesis:
    name: "Genesis Webhook (Week 4-5)"
    tasks:
      - "[ ] FastAPI endpoints (certify/skill, certify/job, validate/agent, precedents/supersede, certify/batch)"
      - "[ ] Genesis 42-point checklist implementation"
      - "[ ] Pub/Sub integration (publish certification results)"
      - "[ ] Redis caching (certification results TTL 24h)"
    
    validation:
      - "Agent self-validates: run all 5 endpoints with PP-generated test agents"
      - "Simulate: Temporal workflow calls Genesis → certification completes"
  
  phase_3_orchestration:
    name: "Temporal Workflows (Week 6-7)"
    tasks:
      - "[ ] Agent Manufacturing Workflow (4 stages)"
      - "[ ] Temporal activities for each stage"
      - "[ ] Compensation logic (rollback on failure)"
      - "[ ] Constitutional drift detection workflow"
    
    validation:
      - "Agent self-validates: run PP-CP simulated agent creation"
      - "Simulate: workflow complete successfully, then test failure + rollback"
  
  phase_4_integration:
    name: "CP/PP Integration (Week 8)"
    tasks:
      - "[ ] Connect Plant services to PP Gateway (port 8015)"
      - "[ ] Connect Plant services to CP Discovery API"
      - "[ ] Test agent certification flow end-to-end"
    
    validation:
      - "Agent self-validates: CP can search certified agents, PP can manage Genesis"
      - "Simulate: complete PP-CP journey with Plant services active"
  
  # AGENT SELF-VALIDATION PROTOCOL
  agent_self_validation:
    protocol: "90%+ coverage achieved when agents validate their own platform"
    
    validation_method_1: "Simulated Journeys"
      - "Agents run PP + CP user journeys with Plant services active"
      - "Each journey exercises Plant endpoints, validates responses"
      - "Coverage metric: % of Plant endpoints called during journeys"
    
    validation_method_2: "Constitutional Checkpoints"
      - "Agents verify L0/L1 enforcement at each stage"
      - "Simulate constitutional drift → verify detection + suspension"
      - "Simulate precedent contradiction → verify escalation"
    
    validation_method_3: "Failure Scenarios"
      - "Agents simulate Genesis unavailability → verify cache fallback"
      - "Agents simulate audit trail tampering → verify detection"
      - "Agents simulate Temporal workflow failure → verify compensation"
    
    success_criteria:
      - "90%+ of Plant API endpoints called by simulated agents"
      - "100% of critical paths (certification, drift detection, compensation) validated"
      - "Zero constitutional breaches detected during validation"
      - "All 8 risks mitigated to acceptable level"

---

## SECTION 9: TECH STACK & ENGINEERING EXCELLENCE
# Phase 0-Enhanced: Approved technologies + testing strategy + code review process + quality standards
# Reference: /main/Foundation/TOOLING_SELECTION_DECISION.md (primary source)
# Principle: Inherited from Foundation + disruptive patterns for Phase 0-ENHANCED

tech_stack_phase_0:
  
  # INHERITED FROM FOUNDATION (Validated ✅)
  approved_technologies:
    database: 
      choice: "PostgreSQL Cloud SQL (db-f1-micro)"
      reference: "TOOLING_SELECTION_DECISION.md (Section 1)"
      mvp_cost: "$15-25/month"
      status: "✅ Approved"
      rationale: "Managed service, RLS policies, pgvector extension, append-only triggers"
    
    orm_migrations:
      choice: "SQLAlchemy 2.0 + Alembic"
      reference: "Standard Python stack"
      mvp_cost: "$0 (open-source)"
      status: "✅ Approved"
      rationale: "Industry standard, type hints support, migration reversibility"
    
    message_bus:
      choice: "Google Cloud Pub/Sub"
      reference: "TOOLING_SELECTION_DECISION.md (Section 2)"
      mvp_cost: "$10-15/month"
      status: "✅ Approved"
      rationale: "Serverless, JSON Schema enforcement, GCP-native"
    
    vector_database:
      choice: "PostgreSQL pgvector extension"
      reference: "PLANT_BLUEPRINT.yaml (Section 2)"
      mvp_cost: "$0 (extension)"
      status: "✅ Approved"
      rationale: "Semantic search for contradiction detection, MiniLM-384 embeddings"
    
    ml_inference:
      choice: "ML Inference Service (8005) + MiniLM-384"
      reference: "architecture_manifest.yml (service registry)"
      mvp_cost: "Included in service"
      status: "✅ Approved"
      rationale: "384-dim embeddings, <500ms latency SLA"
    
    backend_framework:
      choice: "Python 3.11 + FastAPI"
      reference: "architecture_manifest.yml (service specs)"
      mvp_cost: "$0 (open-source)"
      status: "✅ Approved"
      rationale: "Async-native, automatic OpenAPI docs, type hints first-class"
    
    data_validation:
      choice: "Pydantic v2"
      reference: "Standard in FastAPI"
      mvp_cost: "$0 (open-source)"
      status: "✅ Approved"
      rationale: "Runtime validation, BaseEntity 7-section templates, error messages"
    
    deployment:
      choice: "GCP Cloud Run"
      reference: "architecture_manifest.yml (service deployment)"
      mvp_cost: "$0 (included in services)"
      status: "✅ Approved"
      rationale: "Serverless, auto-scaling, 1-10 instances per service"
    
    secrets_management:
      choice: "Google Secret Manager"
      reference: "TOOLING_SELECTION_DECISION.md (Section 3)"
      mvp_cost: "$2-5/month"
      status: "✅ Approved"
      rationale: "Per-secret IAM, audit logging, automatic rotation"
  
  # NEW TECH FOR PHASE 0-ENHANCED (Disruptive Patterns)
  phase_0_enhanced_additions:
    cryptography:
      technology: "Python cryptography library"
      purpose: "RSA-SHA256 signing for non-repudiation"
      pattern: "Cryptographic Accountability (Disruptive Pattern #1)"
      requirement: "All amendments signed + verifiable by third parties"
      status: "⚠️ Needs Architect approval"
      implementation_details:
        algorithm: "RSA-4096 (or RSA-2048 per Architect guidance)"
        hash: "SHA-256"
        key_storage: "Google Secret Manager"
        key_rotation: "Annual"
    
    performance_monitoring:
      technology: "prometheus-client + Google Cloud Monitoring"
      purpose: "SLA tracking (schema migration latency, query performance)"
      pattern: "Self-Validating Entities (Disruptive Pattern #2)"
      requirement: "Monitor <10ms validate_self(), <500ms pgvector queries"
      status: "⚠️ Needs Architect approval"
      implementation_details:
        metrics: "latency_p99, query_count, error_rate"
        dashboard: "Google Cloud Console"
        alerts: "Escalate to Governor if SLA breached"
    
    background_jobs:
      technology: "APScheduler (Python)"
      purpose: "Daily drift detection + auto-regeneration of embeddings"
      pattern: "Continuous Embedding Quality Assurance (Disruptive Pattern #5)"
      requirement: "Stability score >0.85 or regenerate"
      status: "⚠️ Needs Architect approval"
      implementation_details:
        job_name: "EmbeddingQualityMonitor"
        schedule: "Daily at 02:00 UTC (off-peak)"
        action_on_drift: "Auto-regenerate + log to audit_trail + alert Governor"
        phase_evolution: "Phase 0 (APScheduler); Phase 3 (upgrade to Temporal)"
    
    http_client:
      technology: "httpx (async Python)"
      purpose: "Call Genesis Webhook (9001) from BaseEntity validation"
      pattern: "Cost Governance Built-In (Disruptive Pattern #3)"
      requirement: "Pre-authorize queries vs budget before execution"
      status: "✅ Approved (already used in FastAPI stack)"
      implementation_details:
        endpoint: "genesis:9001/authorize-query"
        payload: "customer_id, query_type, estimated_cost"
        timeout: "<100ms (synchronous gate)"
  
  # COST SUMMARY
  total_mvp_cost: "$27-50/month (within $100/month platform budget)"
  cost_breakdown:
    database: "$15-25/month"
    message_bus: "$10-15/month"
    secrets: "$2-5/month"
    monitoring: "$0-5/month"
    infrastructure: "$0 (included in Cloud Run)"

---

## SECTION 10: TESTING STRATEGY
# Comprehensive testing for Phase 0-Enhanced (disruptive foundation)
# Principle: No shortcuts - 90%+ coverage with real databases, cryptography, performance SLAs

testing_layers:
  
  unit_testing:
    framework: "pytest + pytest-cov"
    coverage_target: "≥90% (fail if <90%)"
    coverage_enforcement: "CI/CD gate (pytest-cov plugin)"
    scope:
      - "BaseEntity: all 7 sections independently tested"
      - "Validators: L0/L1 compliance detection"
      - "Cryptography: RSA signing + verification (use real keys)"
      - "Hash chain: SHA-256 link validation"
      - "Error cases: invalid amendments, broken chains"
    
    example_test_files:
      - "tests/unit/test_base_entity.py (100+ test cases)"
      - "tests/unit/test_cryptography.py (signature verification)"
      - "tests/unit/test_validators.py (constitutional alignment)"
  
  integration_testing:
    framework: "pytest + testcontainers + PostgreSQL"
    scope:
      - "Database: RLS policies (cross-customer query attempts blocked)"
      - "Append-only: UPDATE/DELETE constraints enforced"
      - "Hash chain: immutable audit trail"
      - "Semantic search: pgvector queries <500ms"
      - "Workflow: SchemaEvolutionWorkflow (3-gate approval)"
    
    test_infrastructure:
      database: "PostgreSQL Docker container (testcontainers)"
      redis: "Redis Docker container (for cache testing)"
      ml_inference: "Mock ML service (or local test instance)"
    
    example_test_files:
      - "tests/integration/test_database_rls.py (policy isolation)"
      - "tests/integration/test_audit_trail.py (immutability)"
      - "tests/integration/test_workflow.py (genesis → architect → guardian)"
  
  performance_testing:
    framework: "pytest-benchmark"
    slas:
      validate_self: "<10ms (on property access)"
      evolve: "<5ms (amendment creation)"
      verify_amendment: "<20ms (RSA signature verification)"
      pgvector_search: "<500ms (including network latency)"
      schema_migration: "<10% latency increase post-migration"
    
    test_approach: "Benchmark against production-like data volumes"
    example_test_files:
      - "tests/performance/test_latency_slas.py"
  
  security_testing:
    framework: "cryptography.hazmat + pytest"
    scope:
      - "RSA signature verification: non-repudiation validated"
      - "No hardcoded secrets: git-secrets check"
      - "No SQL injection: parameterized queries only"
      - "RLS policy bypass: comprehensive policy testing"
      - "Audit trail tampering: hash chain integrity"
    
    scanning_tools:
      bandit: "Detect crypto misuse, injection vulnerabilities (CI/CD gate)"
      git_secrets: "Block commits with hardcoded secrets"
    
    example_test_files:
      - "tests/security/test_rsa_verification.py (third-party verification)"
      - "tests/security/test_rls_bypass.py (policy isolation)"

---

## SECTION 11: CODE REVIEW PROCESS
# 3-Level gates ensuring architecture alignment, cryptographic correctness, disruptiveness

code_review_gates:
  
  gate_1_automated_checks:
    name: "CI/CD Pipeline"
    turnaround: "<5 minutes"
    required_passes:
      - "pytest (unit + integration tests)"
      - "coverage >90% (fail if <90%)"
      - "mypy --strict (no Any types)"
      - "black formatting (auto-fix or fail)"
      - "flake8 linting (errors + warnings)"
      - "bandit security scan (no HIGH severity)"
      - "git-secrets (no hardcoded secrets)"
    
    failure_action: "❌ CI/CD fails - PR blocked until fixed"
  
  gate_2_expert_code_review:
    name: "Systems Architect Review"
    turnaround: "<24 hours"
    reviewer: "Systems Architect Agent"
    verification_checklist:
      - "Architecture alignment (PLANT_BLUEPRINT.yaml sections matched)"
      - "BaseEntity 7-section completeness"
      - "Cryptographic implementation (RSA signing correctness)"
      - "Constitutional alignment (L0/L1 enforcement present)"
      - "Error handling (clear messages, no silent failures)"
      - "Documentation (docstrings complete, 5-month durability)"
      - "Type hints (100% coverage, no Any types)"
    
    approval_action: "✅ Architect approves PR (or requests changes)"
    blocker_action: "⏸️ PR paused if Architect requests changes"
  
  gate_3_product_owner_review:
    name: "Product Owner Review (Disruptiveness Check)"
    turnaround: "<24 hours"
    reviewer: "Product Owner (User as PLANT visionary)"
    verification_checklist:
      - "Disruptive patterns implemented (crypto, self-validation, cost, schema, embedding)"
      - "No traditional shortcuts taken (no 'TODO' comments, no one-time validation)"
      - "Story acceptance criteria fully met (BDD scenarios passing)"
      - "5-month durability (context preserved, terminology consistent)"
    
    approval_action: "✅ PO approves PR (or requests changes)"
    blocker_action: "⏸️ PR paused if PO requests changes"

  merge_process:
    merge_trigger: "All 3 gates passed (automated ✅ + Architect ✅ + PO ✅)"
    deployment: "Merge to feature branch → deploy to staging → ready for release"

---

## SECTION 12: ENGINEERING EXCELLENCE STANDARDS
# Mandatory metrics, git workflow, commit standards, quality gates

code_quality_metrics:
  test_coverage:
    target: "≥90% (fail if <90%)"
    enforcement: "CI/CD gate (pytest-cov)"
    scope: "All Phase 0 code (BaseEntity, validators, migrations)"
  
  type_hints:
    target: "100% (no Any types)"
    enforcement: "CI/CD gate (mypy --strict)"
    scope: "All public APIs (functions, classes, methods)"
  
  code_format:
    standard: "Black formatter"
    enforcement: "CI/CD gate (auto-fix or fail)"
  
  linting:
    tool: "Flake8"
    enforcement: "CI/CD gate (E, W, F errors block; warnings allow)"
  
  security_scan:
    tool: "Bandit (Python security)"
    enforcement: "CI/CD gate (block on HIGH/CRITICAL issues)"
  
  docstring_coverage:
    target: "100% for public APIs"
    enforcement: "Manual code review gate"
    format: "Google style (Args, Returns, Raises sections)"
  
  type_annotations:
    target: "Complete (no missing types)"
    enforcement: "Manual code review gate"
    includes: "Function arguments, return types, class attributes"

git_workflow:
  main_branches:
    main: "Production-ready code (PR required, status checks enforced)"
    develop: "Integration branch (all PRs merge here first)"
    current_work: "feature/plant-frontend-backend-scaffold"
  
  feature_branches_phase_0:
    - "feature/US-0001-enhanced-base-entity"
    - "feature/US-0002-enhanced-schema-evolution"
    - "feature/US-0003-enhanced-pgvector-cost-governance"
  
  pr_requirements:
    - "✅ All CI/CD gates passing (tests, lint, security)"
    - "✅ Code review approved (Systems Architect)"
    - "✅ Acceptance criteria verified (Product Owner)"
    - "✅ Commit message follows Conventional Commits standard"
    - "✅ No merge conflicts"
    - "✅ Branch up-to-date with develop"

commit_standards:
  format: "Conventional Commits"
  template: "<type>(<scope>): <subject>\n\n<body>\n\n<footer>"
  
  types_used:
    - "feat: new feature (user story implementation)"
    - "fix: bug fix"
    - "docs: documentation"
    - "test: test additions"
    - "refactor: code restructuring"
  
  scopes_phase_0:
    - "plant-phase0: Phase 0 general"
    - "base-entity: BaseEntity implementation"
    - "schema-evolution: PostgreSQL schema + migration"
    - "pgvector: semantic search + embeddings"
  
  example_commit:
    message: "feat(plant-phase0): implement BaseEntity with crypto signatures"
    body: |
      - Implemented all 7 sections (identity, lifecycle, versioning, constitutional_alignment, audit_trail, metadata, relationships)
      - Added RSA-SHA256 signing for amendment history (non-repudiation)
      - Added continuous_validation() method (runs on property access)
      - 100% test coverage (unit + integration + crypto tests)
    footer: "Relates to: US-0001-ENHANCED\nBlueprint Reference: PLANT_BLUEPRINT.yaml (Section 1)"

quality_gates_hard_stops:
  coverage_under_90: "❌ CI/CD fails, PR blocked"
  any_types_found: "❌ CI/CD fails, PR blocked"
  bandit_high_issue: "❌ CI/CD fails, PR blocked"
  tests_fail: "❌ CI/CD fails, PR blocked"
  hardcoded_secrets: "❌ CI/CD fails, PR blocked"
  architect_requests_changes: "⏸️ PR paused (not merged)"
  po_acceptance_not_met: "⏸️ PR paused (not merged)"

---

---

## SECTION 13: BACKEND SOURCE CODE STRUCTURE
# Physical layout for /src/Plant/BackEnd - designed for Phase 0-Enhanced implementation
# Principle: Layered architecture with clear separation of concerns + testability

backend_structure:
  
  root_level_files:
    main_py:
      purpose: "FastAPI app initialization + middleware setup"
      contains: "CORS, error handlers, route mounting, lifespan events"
      phase_0_focus: "Genesis endpoints + health checks"
    
    requirements_txt:
      purpose: "Pinned production dependencies"
      core_packages: "fastapi, uvicorn, sqlalchemy, psycopg2-binary, pydantic, temporalio, cryptography, redis, prometheus-client"
      testing_packages: "pytest, pytest-cov, pytest-asyncio, testcontainers"
    
    pytest_ini:
      purpose: "Pytest configuration for test discovery + coverage reporting"
      markers: "unit, integration, performance, security (allow categorization)"
    
    dockerfile:
      purpose: "Multi-stage build (builder → runtime)"
      runtime_user: "non-root (security best practice)"
    
    env_example:
      purpose: "Template for .env configuration"
      variables: "DATABASE_URL, REDIS_URL, ML_SERVICE_URL, SECRET_KEY, LOG_LEVEL"

  core_layer:
    purpose: "Configuration, database, security, exceptions"
    files:
      config_py:
        contains: "Pydantic BaseSettings for environment variables"
        loads_from: ".env file (with validation)"
        exports: "Settings singleton used by all layers"
      
      database_py:
        contains: "SQLAlchemy engine + session factory"
        setup: "create_engine(DATABASE_URL), sessionmaker, Base (declarative)"
        exports: "get_db() generator (for FastAPI dependency injection)"
      
      exceptions_py:
        contains: "Custom exception classes for domain errors"
        examples:
          - "ConstitutionalAlignmentError (L0/L1 validation failed)"
          - "HashChainBrokenError (audit trail tampered)"
          - "AmendmentSignatureError (RSA verification failed)"
          - "EntityNotFoundError, ValidationError, DuplicateEntityError"
      
      security_py:
        contains: "JWT token generation + validation, RBAC helpers"
        used_by: "API auth middleware + protected routes"
      
      logging_py:
        contains: "Structured logging setup (JSON format for parsing)"
        exports: "get_logger(name) factory function"

  models_layer:
    purpose: "Pydantic + SQLAlchemy entities (7-section inheritance)"
    files:
      base_entity_py:
        defines: "BaseEntity (root class for all Plant entities)"
        sections:
          - "identity: uuid (primary key), entity_type, external_id"
          - "lifecycle: created_at, updated_at, deleted_at, status"
          - "versioning: version_hash (SHA-256), amendment_history (JSON), evolution_markers"
          - "constitutional_alignment: l0_compliance_status, amendment_alignment, drift_detector"
          - "audit_trail: append_only marker, hash_chain_sha256, tamper_proof flag"
          - "metadata: tags (array), custom_attributes (JSON), governance_notes"
          - "relationships: parent_id, child_ids (array), governance_agent_id"
        methods:
          - "validate_self() → ComplianceStatus (runs on property access)"
          - "evolve() → creates new version_hash, appends amendment"
          - "sign_amendment() → RSA signature for non-repudiation"
          - "verify_amendment() → validate signature (third-party verifiable)"
          - "get_hash_chain_integrity() → validate SHA-256 links"
        inheritance: "Pydantic v2 dataclass + SQLAlchemy ORM hybrid"
      
      skill_py:
        inherits_from: "BaseEntity"
        attributes:
          - "name (string, unique)"
          - "description (text)"
          - "category (enum: marketing, education, sales)"
          - "embedding_384 (pgvector(384), MiniLM-generated)"
          - "genesis_certification (JSON: certification_id, date, signature_hash)"
      
      job_role_py:
        inherits_from: "BaseEntity"
        attributes:
          - "name (string, unique)"
          - "required_skills (array of Skill IDs)"
          - "seniority_level (enum: junior, mid, senior)"
          - "industry_id (FK to Industry)"
      
      team_py:
        inherits_from: "BaseEntity"
        attributes:
          - "name (string, unique)"
          - "agents (array of Agent IDs)"
          - "job_role_id (FK to JobRole)"
          - "skills (computed from union of agent skills)"
      
      agent_py:
        inherits_from: "BaseEntity"
        attributes:
          - "name (string, unique)"
          - "skill_id (FK to Skill)"
          - "job_role_id (FK to JobRole)"
          - "team_id (FK to Team)"
          - "industry_id (FK to Industry, locked after birth)"
      
      industry_py:
        inherits_from: "BaseEntity"
        attributes:
          - "name (string, unique)"
          - "agents (array of Agent IDs)"
          - "embedding_384 (pgvector(384), for contradiction detection)"
      
      schemas_py:
        purpose: "Pydantic request/response schemas (separate from ORM)"
        pattern: "SkillCreate (POST), SkillResponse (GET), SkillUpdate (PUT)"
        benefit: "API contract stable even if ORM changes"

  validators_layer:
    purpose: "Constitutional + business logic validation"
    files:
      constitutional_validator_py:
        checks:
          - "L0-01: governance_agent_id present (governance chain)"
          - "L0-02: amendment_history tracked (no deletions)"
          - "L0-03: append-only enforced (no UPDATEs to past amendments)"
          - "L0-04: supersession chain preserved (entity evolution trackable)"
          - "L0-05: compliance gate possible (validation result exportable)"
          - "L1 checks: entity-specific rules (e.g., Skill + JobRole + Team unique per Agent)"
      
      entity_validator_py:
        checks:
          - "Skill uniqueness (name per industry)"
          - "JobRole: required_skills not empty"
          - "Team: agents not empty, all agents have compatible skills"
          - "Agent: Skill + JobRole + Team combination unique"
          - "No circular parent-child relationships"
      
      schema_evolution_validator_py:
        checks:
          - "Migration: no breaking changes without 3-gate approval"
          - "Migration: RLS policies present before schema change"
          - "Migration: auto-rollback if latency increases >10%"

  security_layer:
    purpose: "Cryptographic operations + tamper-proofing"
    files:
      cryptography_py:
        functions:
          - "generate_rsa_keypair() → (private_key, public_key)"
          - "sign_data(data, private_key) → RSA-SHA256 signature"
          - "verify_signature(data, signature, public_key) → boolean"
        key_storage: "Google Secret Manager (not in code)"
        key_rotation: "Annual (scheduled job)"
      
      hash_chain_py:
        functions:
          - "calculate_sha256(data) → hex digest"
          - "create_hash_link(previous_hash, current_data) → new_hash"
          - "validate_chain(hashes: list) → boolean (all links valid)"
          - "detect_tampering(amendment_history) → TamperDetectionResult"
      
      amendment_signer_py:
        high_level_api: "sign_amendment(entity, change_description) → signed_amendment"
        verification_api: "verify_amendment_authenticity(amendment, governance_agent_id) → boolean"

  database_layer:
    purpose: "Schema version control + RLS policies + test fixtures"
    files:
      init_db_py:
        creates: "All tables from models (SQLAlchemy metadata.create_all())"
        applies_rls: "Run RLS policies from rls_policies.sql"
      
      migrations_env_py:
        alembic_environment: "Configuration for autogenerate + migration execution"
      
      migrations_versions:
        001_base_entity_schema_py:
          creates: "base_entity table with 7 sections + indexes"
        
        002_skill_entity_py:
          creates: "skill_entity table + indexes (name, category, embedding)"
          indexes: "btree on name, category; GiST on embedding_384"
        
        003_job_role_entity_py:
          creates: "job_role_entity table + FK to skill_entity (array type)"
        
        004_team_entity_py:
          creates: "team_entity table + FK constraints"
        
        005_agent_entity_py:
          creates: "agent_entity table + unique constraint (skill + role + team + industry)"
        
        006_rls_policies_py:
          runs: "rls_policies.sql"
          policies_applied:
            - "base_entity: customer isolation (RLS enabled)"
            - "skill_entity: team-scoped (inherited from BaseEntity RLS)"
            - "All tables: UPDATE/DELETE blocked on audit columns"
        
        007_pgvector_setup_py:
          creates: "pgvector extension (if not exists)"
          creates_indexes: "IVFFlat index on embedding_384 (similarity search)"
      
      fixtures_py:
        seed_functions:
          - "create_test_skills(count=5) → list of Skill objects"
          - "create_test_job_roles(skills) → list of JobRole objects"
          - "create_test_team(job_role, agents) → Team object"
          - "create_test_agents(count=10) → list of Agent objects"
      
      rls_policies_sql:
        policies:
          - "SELECT: users can only see own customer data (via customer_id)"
          - "INSERT: restricted to owner + governance agents"
          - "UPDATE: audit columns immutable (hash_chain, created_at)"
          - "DELETE: forbidden (data retention requirement)"

  ml_layer:
    purpose: "Embedding generation + caching + quality monitoring"
    files:
      inference_client_py:
        calls: "ML Inference Service (8005) for MiniLM-384 embeddings"
        retry_strategy: "Exponential backoff (3 attempts max)"
        timeout: "<100ms per request"
      
      embedding_cache_py:
        uses: "Redis for embedding cache (key: content_hash, value: embedding)"
        ttl: "24 hours (configurable)"
      
      embedding_quality_py:
        stability_score: "Measures embedding drift (0.0-1.0, target >0.85)"
        drift_detection: "Daily job compares old vs new embeddings"
      
      embedding_regenerator_py:
        trigger: "If stability_score <0.85"
        action: "Auto-regenerate embedding + log to audit_trail"
        notification: "Alert Governor via Pub/Sub"

  workflows_layer:
    purpose: "Temporal workflow definitions for complex orchestration"
    files:
      genesis_certification_workflow_py:
        steps:
          - "1. Validate entity (L0/L1 checks via constitutional_validator)"
          - "2. Submit to Genesis agent for approval"
          - "3. Record certification (signature + timestamp)"
          - "4. Return certification_id"
      
      schema_evolution_workflow_py:
        steps:
          - "Gate 1: Genesis validates L0/L1 (no breaking changes)"
          - "Gate 2: Architect validates performance (latency <10% increase)"
          - "Gate 3: Vision Guardian validates constitutional alignment"
          - "4. Execute migration (or auto-rollback if SLA failed)"
      
      cost_governance_workflow_py:
        async_execution: "Pre-authorize query vs customer budget"
        queues: "Queries at limit, auto-retry when budget refreshes"

  api_layer:
    purpose: "FastAPI routes (thin layer, delegates to services)"
    structure:
      api_v1_genesis_jobs_py:
        endpoints:
          - "POST /genesis/jobs → create job"
          - "POST /genesis/jobs/{id}/certify → certify job"
      
      api_v1_genesis_skills_py:
        endpoints:
          - "POST /genesis/skills → create skill"
          - "POST /genesis/skills/{id}/certify → certify skill"
      
      api_v1_agents_routes_py:
        endpoints:
          - "POST /agents → create agent"
          - "GET /agents/{id} → get agent"
          - "PUT /agents/{id} → update agent"
      
      api_v1_simulation_routes_py:
        endpoints:
          - "POST /simulation/run → execute simulation"
          - "GET /simulation/{id}/results → get results"
      
      api_v1_audit_routes_py:
        endpoints:
          - "POST /audit/run → run compliance audit"
          - "GET /audit/{id}/results → get audit results"

  services_layer:
    purpose: "Business logic (isolated from HTTP)"
    files:
      skill_service_py:
        methods:
          - "create_skill() → Skill (validates constitutional alignment)"
          - "certify_skill() → triggers genesis_certification_workflow"
      
      job_role_service_py:
        methods:
          - "create_job_role() → JobRole"
          - "validate_skills_exist() → boolean"
      
      agent_service_py:
        methods:
          - "create_agent() → Agent (validates Skill + JobRole + Team unique)"
          - "lock_industry() → prevents industry change after creation"
      
      audit_service_py:
        methods:
          - "run_compliance_audit() → AuditResult (L0/L1 checks)"
          - "detect_tampering() → list of TamperDetectionResults"

  tests_layer:
    purpose: "Comprehensive test coverage (unit, integration, performance, security)"
    structure:
      conftest_py:
        fixtures:
          - "db_session (pytest-testcontainers with PostgreSQL)"
          - "app (FastAPI test client)"
          - "mock_ml_service (mocked ML inference endpoint)"
          - "test_skills, test_job_roles, test_agents (seeded fixtures)"
      
      unit_test_base_entity_py:
        tests:
          - "test_base_entity_creation (all 7 sections initialized)"
          - "test_validate_self (L0/L1 checks pass)"
          - "test_evolve (version_hash updated, amendment appended)"
          - "test_sign_amendment (RSA signature generated)"
          - "test_verify_amendment (signature verifies correctly)"
          - "test_hash_chain_integrity (all SHA-256 links valid)"
      
      unit_test_validators_py:
        tests:
          - "test_l0_compliance_checks (governance_agent_id present)"
          - "test_l1_compliance_checks (entity-specific rules)"
          - "test_entity_uniqueness (Skill + JobRole + Team per Agent)"
      
      unit_test_cryptography_py:
        tests:
          - "test_rsa_keypair_generation"
          - "test_sign_and_verify (signature validates)"
          - "test_signature_tampering_detected (modified signature fails)"
          - "test_no_weak_algorithms (only RSA-4096, SHA-256)"
      
      integration_test_database_rls_py:
        tests:
          - "test_rls_cross_customer_blocked (customer A cannot see customer B data)"
          - "test_rls_insert_restricted (only owner + governance agents can insert)"
          - "test_append_only_constraints (UPDATE/DELETE rejected on audit columns)"
      
      integration_test_workflows_py:
        tests:
          - "test_genesis_certification_workflow (end-to-end)"
          - "test_schema_evolution_workflow (3-gate approval)"
      
      performance_test_latency_slas_py:
        benchmarks:
          - "validate_self() <10ms"
          - "evolve() <5ms"
          - "verify_amendment() <20ms"
          - "pgvector_search() <500ms"
      
      security_test_rls_bypass_py:
        tests:
          - "test_direct_sql_injection_blocked"
          - "test_rls_policy_bypass_attempts"
          - "test_audit_trail_tampering_detected"

  middleware_layer:
    purpose: "Cross-cutting concerns"
    files:
      error_handler_py:
        catches: "All exceptions → standardized JSON response"
      
      logging_middleware_py:
        logs: "request_id, method, path, status_code, latency"
      
      cost_governance_middleware_py:
        intercepts: "Queries → checks budget before execution"
      
      correlation_id_py:
        generates: "Trace ID for distributed tracing"

  scripts_layer:
    purpose: "Utility commands for development + deployment"
    files:
      init_db_local_sh:
        runs: "Creates local PostgreSQL database + applies migrations"
      
      run_migrations_sh:
        runs: "alembic upgrade head (or specific revision)"
      
      seed_test_data_sh:
        runs: "Loads test fixtures (skills, jobs, agents)"
      
      benchmark_sh:
        runs: "pytest with performance markers + reports latency"

backend_structure_principles:
  - "✅ Layered: Each layer has single responsibility"
  - "✅ Testable: No dependencies between layers (invert for testing)"
  - "✅ Traceable: Models inherit from BaseEntity (7 sections)"
  - "✅ Secure: Cryptography isolated in security/ layer"
  - "✅ Auditable: All changes append-only to amendment_history"
  - "✅ Performant: Migrations indexed, pgvector optimized, SLAs enforced"
  - "✅ Disruptive: Cost governance, embedding quality, schema evolution workflows"

implementation_order_phase_0:
  - "1. core/ (config, database, exceptions)"
  - "2. models/ (BaseEntity + schemas)"
  - "3. database/ (migrations, RLS policies)"
  - "4. validators/ (constitutional checks)"
  - "5. security/ (cryptography, hash chains)"
  - "6. tests/ (fixtures, unit tests for #2-5)"
  - "7. services/ (skill, job_role, agent services)"
  - "8. api/ (Genesis endpoints)"
  - "9. middleware/ (error handling, logging)"

---

## SECTION 8: REFERENCES & TRACEABILITY
# Every architectural decision traces back to Foundation documents (data lineage)

references:
  
  foundation_architecture:
    - "/main/Foundation/Foundation.md (constitutional framework)"
    - "/main/Foundation/architecture_decision_records.md (15 ADRs including ADR-007)"
    - "/main/Foundation/architecture_manifest.yml (17 backend services registry)"
    - "/main/Foundation/WAOOAW_COMPONENT_ARCHITECTURE.md (layered architecture)"
    - "/main/Foundation/TOOLING_SELECTION_DECISION.md (PostgreSQL, Pub/Sub, Redis, Temporal)"
  
  governance_agents:
    - "/main/Foundation/genesis_foundational_governance_agent.md (Genesis charter)"
    - "/main/Foundation/vision_guardian_foundational_governance_agent.md (Vision Guardian charter)"
    - "/main/Foundation/governor_agent_charter.md (Governor authority)"
  
  base_entity_pattern:
    - "/main/Foundation/template/base_entity.yml (universal inheritance)"
  
  plant_journey:
    - "/docs/plant/user_journey/PORTAL_USER_JOURNEY.md (5 folds + 15 API endpoints)"
    - "/docs/plant/user_journey/PORTAL_USER_JOURNEY.yaml (structured specification)"
    - "/src/Plant/session_update.md (architectural learnings + context)"
  
  related_portals:
    - "/docs/CP/CUSTOMER_PORTAL_JOURNEY.md (CP integration with Plant)"
    - "/docs/PP/PORTAL_USER_JOURNEY.md (PP integration with Plant)"

---

## GOLDEN SOURCE STATUS

blueprint_validation:
  - "✅ Single Document: All architecture in one YAML (not scattered across files)"
  - "✅ Constitutional Alignment: L0/L1 enforcement at every layer"
  - "✅ Traceable: Every decision references Foundation documents"
  - "✅ Inventory-Based: Start with clear list (5 entities, 17 services, 8 governance workflows)"
  - "✅ Agent-Maintained: Workflows enable agents to self-validate 90%+ coverage"
  - "✅ Risk Framework: 8 risks identified + mitigations designed into infrastructure"
  - "✅ Disruptive + Low-Cost: Temporal for orchestration, pgvector for embeddings, Cloud Run for hosting"
  - "✅ Tech Stack & Excellence: 12 sections covering tech decisions, testing strategy, code review gates, engineering standards"
  - "✅ Complete Coverage: Blueprint now includes SECTIONS 1-12 (entities, infrastructure, orchestration, governance, risks, implementation, references, tech stack, testing, review, excellence, validation)"

ready_for_implementation: true
approval_status: "Awaiting Governor + Systems Architect sign-off"
blueprint_version: "1.1 - 2026-01-14 (added Sections 9-12: Tech Stack & Engineering Excellence)"

