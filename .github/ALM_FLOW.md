# WAOOAW ALM Workflow (Master)

**Version**: 2.2  
**Date**: 2026-01-21  
**Status**: Active on `main` - Aligned with YAML implementation  
**Owner**: Governor + Vision Guardian governance  
**Golden Source**: `.github/workflows/project-automation.yml`  

This document is the master reference for WAOOAW’s autonomous Application Lifecycle Management (ALM) workflow.

---


## Objectives

- **End-to-end autonomy**: Creating an Epic triggers governance → decomposition → delivery with minimal manual intervention
- **Constitution-first**: Vision Guardian (VG) enforces alignment before downstream execution
- **Python script-based agents**: Code/Test/Deploy agents use Python scripts (`scripts/*_agent.py`) that call GitHub Models API to generate real code
- **Governor gates**: Human `go-coding` label required before Coding Agent executes (prevents premature implementation)
- **Strict standards**: Generated code includes type hints, docstrings, tests (enforced by agent scripts + CI)
- **Reliability by design**: Job chaining with `needs` + concurrency groups prevent race conditions
- **Traceability**: BA creates user story issues; closure triggers downstream agents
- **Idempotency**: Completion labels (`ba-complete`, `sa-complete`, `testing-complete`) prevent duplicate runs

---

## Introduction

WAOOAW orchestrates specialized agents through GitHub Issues and GitHub Actions.

- **Epic issues** are the canonical contract for outcomes and constraints.
- **User story issues** are the executable backlog.
- **Issue comments** are agent deliverables (analysis, decisions, handoffs) posted directly to the epic.

The orchestrator is implemented in `.github/workflows/project-automation.yml`.

---

## System Design

### Orchestrator workflow

**Workflow**: `.github/workflows/project-automation.yml`

**Events**:

- `issues`: `opened`, `labeled`, `closed`, `reopened`
- `issue_comment`: `created`
- `pull_request`: `opened`, `closed`, `reopened`

### Critical GitHub Actions constraint (key architectural fact)

GitHub Actions does **not reliably start new workflow runs** from events generated by automation using the repository token (example: a job applies a label, expecting another `issues:labeled` run).

**Design implication**: Any ALM stage that depends on “bot applied label triggers next stage” is prone to silent stalls.

**Mitigation adopted**:

- Chain stages in the **same workflow run** using `needs` + job outputs.
- Use **human-driven** events for stage changes where appropriate (e.g., story closure by a human).
- Add **idempotency guards** and **concurrency** to prevent duplicates when multiple events fire.

### Reliability primitives

- **Concurrency groups**: `vg-${{issue}}`, `ba-sa-${{issue}}`, `testing-${{epic}}`, `deploy-${{epic}}` with `cancel-in-progress: true`
- **Idempotency guards**: Jobs check for existing comments ("VG Part 1/7") or issues (BA stories) before creating
- **Completion labels**: `ba-complete`, `sa-complete`, `testing-complete` prevent duplicate agent runs
- **Job chaining**: Uses `needs:` to enforce ordering (VG → BA/SA → Coding → Testing → Deploy)

---

## Data Model (Issues + Labels)

### Issue types

- **Epic**: Issue labeled `epic`.
- **User story**: Issue labeled `user-story` plus a linkage label `epic-<EPIC_NUMBER>`.

### Labels (core)

**Governance**:
- `epic`, `vision-guardian-agent`, `vision-guardian-review`, `vg-approved`
- `go-coding` - Governor gate: required before Code Agent can execute

**Decomposition**:
- `business-analyst`, `systems-architect`
- `ba-complete`, `sa-complete` - Completion markers

**Delivery**:
- `user-story`, `epic-<NUMBER>` - Story linkage to epic
- `code-agent` - Triggers autonomous Code Agent (scripts/code_agent.py)
- `coding-agent`, `testing-agent`, `deployment-agent` - Agent execution markers
- `testing-complete` - Test Agent finished successfully

**Escalation**:
- `escalation-attempt-1/2/3`, `governor-final-decision`

---

## Flow (Current Implementation)

### 1) Create Epic

Governor creates an Issue with label `epic` and a body including:

- Business goal, scope boundaries
- Success metrics
- Constraints (demo-only deployment, docs policy, etc.)

### 2) Auto-Triage

Trigger: `issues:opened` (and sometimes `issues:labeled`).

Responsibilities:

- Adds routing labels for VG.
- Creates an **epic branch immediately** and posts a comment with the branch name.

### 3) Vision Guardian (VG)

VG posts the **7-part** analysis directly on the epic as comments, then (when qualifying) triggers auto-approval:

- Adds `vg-approved`
- Adds BA/SA labels

VG is **deduped** (concurrency + idempotency) so it should post once.

### 4) BA + SA (chained after VG)

BA and SA run in `autonomous-ba-sa-trigger` job with:
- `needs: [autonomous-vg-analysis, auto-triage]` - Waits for VG completion
- `concurrency: ba-sa-${{issue}}` - Prevents duplicate runs

**BA Agent**:
- Creates **5 user story issues** (not comments) with labels: `user-story`, `epic-<NUMBER>`, priority
- **Auto-labels stories with `code-agent`** if epic has `go-coding` label (enables immediate coding)
- Posts summary comment with RICE scores + traceability matrix
- Applies `ba-complete` label to epic

**SA Agent**:
- Posts **5 chunked comments** on epic: Overview, STRIDE, Performance, Tech Debt, ADR
- Applies `sa-complete` label when finished


### 5) Coding (Python script-based)

**Trigger**: User story labeled `code-agent`

**Job**: `autonomous-code-agent`
- Runs `scripts/code_agent.py` with story details
- Script calls GitHub Models API to generate production code
- Commits generated code to epic branch with git
- Enforces: PEP8, type hints, docstrings, no secrets, testability

**Implementation PR**:
- Created by `trigger-coding-agent` job when **last story closes** (if `go-coding` label present)
- Draft PR from epic branch → main
- All code commits update this single PR

**Governor Gate**: Epic must have `go-coding` label or Coding Agent won't run (prevents premature implementation)


### 6) Testing (Python script-based, chained)

**Trigger**: Last user story closed + `go-coding` label present

**Job**: `trigger-testing-agent`
- `needs: [trigger-coding-agent]` - Runs after coding complete
- `concurrency: testing-${{epic}}` - One test run per epic
- Checkouts epic branch, runs `scripts/test_agent.py`
- Script generates tests via GitHub Models, commits them, runs pytest
- Applies `testing-agent` + `testing-complete` labels
- **Fail-closed**: If pytest fails, workflow fails (no deployment)


### 7) Deployment (Python script-based, chained)

**Trigger**: Testing Agent success

**Job**: `trigger-deployment-agent`
- `needs: [trigger-testing-agent, trigger-coding-agent]` - Runs after tests pass
- `concurrency: deploy-${{epic}}` - One deploy per epic
- Checkouts epic branch, runs `scripts/deploy_agent.py`
- Script generates K8s manifests/Terraform/CI pipelines via GitHub Models
- Commits deployment assets to epic branch
- Applies `deployment-agent` label
- **Does NOT execute cloud deployment** - merge approval required first

---

### 8) Escalation Handler (autonomous)

**Trigger**: Issue comment contains `[ESCALATION]`

**Job**: `autonomous-escalation-handler`
- Validates format: requires **3 probable solutions** (per Operational Guidelines)
- Tracks escalation attempts (1/3, 2/3, 3/3)
- Routes to target agent based on "Escalation To:" field
- **Auto-escalates to Governor** on 3rd attempt (RULE #2)
- Governor decision is **FINAL** (no further loops)
- Labels: `escalation-attempt-N`, `governor-final-decision`

---

## Implementation Details


### Architecture

**Orchestrator**: `.github/workflows/project-automation.yml` (2200+ lines)
- All jobs, triggers, conditions, concurrency groups
- Label management, comment posting, issue creation
- Git operations (branch creation, checkout, commit, push)

**Agent Scripts** (Python):
- `scripts/code_agent.py` - Calls GitHub Models to generate production code
- `scripts/test_agent.py` - Generates tests via GitHub Models, runs pytest
- `scripts/deploy_agent.py` - Generates K8s/Terraform/CI via GitHub Models

**Agent Execution Pattern**:
1. Workflow checks out epic branch
2. Runs Python agent script with `--epic-number`, `--issue-number` args
3. Script calls GitHub Models API (gpt-4o via `GITHUB_TOKEN`)
4. Script writes generated files to disk
5. Script uses git CLI to commit and push
6. Workflow adds labels and posts summary comment

### Expected behavior: “one run cancelled, one succeeded”

It is normal to see one run **cancelled** and another **succeeded** for the same epic creation.

Reason: multiple triggers can start runs (`opened` + `labeled`). Concurrency ensures only one completes to avoid duplicate comments.

---


## Testing & Verification

### Recommended end-to-end validation

1. Create epic (label `epic`) → Auto-triage creates epic branch
2. VG posts 7 chunked comments → Auto-approves if score ≥80
3. BA creates 5 user story issues (labeled `user-story`, `epic-<n>`)
4. SA posts 5 chunked architecture comments
5. **Governor applies `go-coding` label** to epic (manual gate)
6. Label user story with `code-agent` → `scripts/code_agent.py` runs, commits code
7. Close last user story → Implementation PR created (draft)
8. Test Agent runs `scripts/test_agent.py` → commits tests, runs pytest
9. Deploy Agent runs `scripts/deploy_agent.py` → commits K8s/Terraform
10. Review Implementation PR (must be green) → Merge to deploy

### What “good” looks like (recent validation)

Epic #191 demonstrated:

- Branch created comment
- VG 1/7..7/7 posted
- Auto-approval occurred
- BA created story issues #192..#196
- SA posted all 5 parts (STRIDE, performance, ADR, etc.)

---

## Troubleshooting

### VG duplicates

If VG ever posts twice:

- Check idempotency markers (“VG Analysis - Part 1/7”) and concurrency settings.
- Verify the epic didn’t get edited/relabeled in a way that bypasses the guard.

### BA/SA didn’t run

Historically caused by bot-applied label events not producing a new run.

Current design should avoid this. If it happens:

- Check that VG approval condition was met.
- Inspect the Actions run and ensure BA/SA job conditions evaluated true.

### Testing/Deployment didn’t trigger

- Confirm you closed user stories as a human.
- Confirm the “last story closed” condition is satisfied.
- Inspect job outputs from Coding and ensure they flow into Testing/Deployment.

---

## Future Enhancements

- **Agent script robustness**: Retry logic, better error messages, token limit handling
- **Metrics dashboard**: Time-to-branch, time-to-VG, time-to-first-PR, story completion velocity
- **Dry-run mode**: `simulate` label for analysis without execution
- **Code quality gates**: Enforce coverage % in Test Agent, SAST in Code Agent
- **Governor dashboard**: Epic health view (VG score, story progress, CI status)

---


## Change Log

- **v2.2 (2026-01-21)**: Documentation aligned with YAML golden source.
  - Documented `go-coding` Governor gate (prevents premature coding)
  - Documented Python script-based agent execution (code_agent.py, test_agent.py, deploy_agent.py)
  - Added concurrency group details (vg-${{issue}}, ba-sa-${{issue}}, testing/deploy-${{epic}})
  - Documented BA auto-labeling behavior (applies `code-agent` when `go-coding` present)
  - Added Escalation Handler section (3-attempt rule, Governor final decision)
  - Documented Implementation PR creation timing (last story close)
  - Added `testing-complete` label to data model
- **v2.1 (2026-01-21)**: Autonomous agent code/test/deploy wiring (Python scripts via GitHub Models)
- **v2.0 (2026-01-20)**: VG posts on epic, branch creation in triage, BA creates issues, reliability improvements
