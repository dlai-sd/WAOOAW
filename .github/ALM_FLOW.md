# WAOOAW ALM Workflow (Master)

**Version**: 2.1  
**Date**: 2026-01-21  
**Status**: Active on `main`  
**Owner**: Governor + Vision Guardian governance  

This document is the master reference for WAOOAW’s autonomous Application Lifecycle Management (ALM) workflow.

---


## Objectives

- **End-to-end autonomy**: Creating an Epic triggers governance → decomposition → delivery with minimal manual intervention.
- **Constitution-first**: Vision Guardian (VG) enforces alignment with WAOOAW constitutional documents before downstream execution.
- **Autonomous code/test/deploy**: Code, Test, and Deployment agents generate, commit, and PR world-class code, tests, and scripts using LLMs (Claude 4.5, GPT-5.2).
- **Strict standards**: All generated code/tests/scripts follow best practices (PEP8, Black, type hints, docstrings, 100% testable, no secrets).
- **Reliability by design**: No fragile “bot adds label → new run starts” dependencies; use job chaining + idempotency.
- **Traceability**: Business Analyst (BA) creates **user story issues** (not comments) so closure can drive the pipeline.
- **Controlled execution**: Least-privilege permissions, safe defaults, and explicit manual override paths.

---

## Introduction

WAOOAW orchestrates specialized agents through GitHub Issues and GitHub Actions.

- **Epic issues** are the canonical contract for outcomes and constraints.
- **User story issues** are the executable backlog.
- **Issue comments** are agent deliverables (analysis, decisions, handoffs) posted directly to the epic.

The orchestrator is implemented in `.github/workflows/project-automation.yml`.

---

## System Design

### Orchestrator workflow

**Workflow**: `.github/workflows/project-automation.yml`

**Events**:

- `issues`: `opened`, `labeled`, `closed`, `reopened`
- `issue_comment`: `created`
- `pull_request`: `opened`, `closed`, `reopened`

### Critical GitHub Actions constraint (key architectural fact)

GitHub Actions does **not reliably start new workflow runs** from events generated by automation using the repository token (example: a job applies a label, expecting another `issues:labeled` run).

**Design implication**: Any ALM stage that depends on “bot applied label triggers next stage” is prone to silent stalls.

**Mitigation adopted**:

- Chain stages in the **same workflow run** using `needs` + job outputs.
- Use **human-driven** events for stage changes where appropriate (e.g., story closure by a human).
- Add **idempotency guards** and **concurrency** to prevent duplicates when multiple events fire.

### Reliability primitives

- **Concurrency**: Only one “winner” run per epic; duplicates are cancelled.
- **Idempotency**: Jobs check for existing markers (e.g., VG Part 1/7 comment) before posting.
- **Completion labels**: `ba-complete`, `sa-complete` to allow safe re-runs.

---

## Data Model (Issues + Labels)

### Issue types

- **Epic**: Issue labeled `epic`.
- **User story**: Issue labeled `user-story` plus a linkage label `epic-<EPIC_NUMBER>`.

### Labels (core)

Governance:

- `epic`
- `vision-guardian-agent`, `vision-guardian-review`, `vg-approved`

Decomposition:

- `business-analyst`, `systems-architect`
- `ba-complete`, `sa-complete`

Delivery stages:

- `user-story`
- `coding-agent`, `testing-agent`, `deployment-agent`

---

## Flow (Current Implementation)

### 1) Create Epic

Governor creates an Issue with label `epic` and a body including:

- Business goal, scope boundaries
- Success metrics
- Constraints (demo-only deployment, docs policy, etc.)

### 2) Auto-Triage

Trigger: `issues:opened` (and sometimes `issues:labeled`).

Responsibilities:

- Adds routing labels for VG.
- Creates an **epic branch immediately** and posts a comment with the branch name.

### 3) Vision Guardian (VG)

VG posts the **7-part** analysis directly on the epic as comments, then (when qualifying) triggers auto-approval:

- Adds `vg-approved`
- Adds BA/SA labels

VG is **deduped** (concurrency + idempotency) so it should post once.

### 4) BA + SA (chained after VG)

BA and SA run after VG approval in a reliable way (no dependence on bot-label-triggered runs).

- **BA** creates **5 user story issues**.
- **SA** posts architecture deliverables (STRIDE, performance architecture, ADR, etc.).


### 5) Coding (autonomous, story-driven)

Trigger: user story labeled `code-agent` (or closed, legacy).

- **Code Agent** is invoked automatically and uses LLMs (Claude 4.5, GPT-5.2) to generate production-grade code for the story.
- Code is written to the repo, committed, and pushed to a new branch by the agent.
- A PR is opened for human review and CI/CD validation.
- Coding standards are strictly enforced in the LLM prompt (PEP8, Black, type hints, docstrings, no secrets, 100% testable).
- If no code is generated, the workflow fails and notifies the Governor.


### 6) Testing (autonomous, chained)

- **Test Agent** is invoked after Coding and uses LLMs to generate and commit tests for the new code.
- Tests are written, committed, and PR’d by the agent.
- All tests must pass in CI before merge.


### 7) Deployment (autonomous, chained)

- **Deployment Agent** is invoked after Testing passes and uses LLMs to generate/update deployment scripts (Docker, K8s, CI/CD YAML, etc.).
- Deployment scripts are committed and PR’d by the agent.
- Deployment only proceeds if all CI gates are green and PR is human-approved.

---

## Implementation Details


### Where to look

- Orchestrator: `.github/workflows/project-automation.yml`
- Code Agent: `scripts/code_agent.py` (calls LLMs, writes/commits code, opens PR)
- Test/Deploy Agent: (future) `scripts/test_agent.py`, `scripts/deploy_agent.py`

All agent actions are performed via GitHub Actions workflow steps and scripts:

- Read labels/body
- Add labels
- Post comments
- Create BA story issues
- Call LLM APIs to generate code/tests/scripts
- Write, commit, and push code/tests/scripts
- Open PRs for human review

### Expected behavior: “one run cancelled, one succeeded”

It is normal to see one run **cancelled** and another **succeeded** for the same epic creation.

Reason: multiple triggers can start runs (`opened` + `labeled`). Concurrency ensures only one completes to avoid duplicate comments.

---


## Testing & Verification

### Recommended end-to-end validation

1. Create a fresh epic (label `epic`).
2. Confirm branch creation comment appears.
3. Confirm VG posts Parts 1/7 → 7/7 once.
4. Confirm `vg-approved` appears (if score qualifies).
5. Confirm BA creates 5 user story issues labeled `user-story` + `epic-<n>`.
6. Label a user story with `code-agent` and confirm Code Agent generates, commits, and PRs code.
7. Confirm PR passes CI and is human-reviewed.
8. Confirm Test Agent generates and PRs tests (future).
9. Confirm Deployment Agent generates and PRs deployment scripts (future).
10. Confirm Testing and Deployment chain as before.

### What “good” looks like (recent validation)

Epic #191 demonstrated:

- Branch created comment
- VG 1/7..7/7 posted
- Auto-approval occurred
- BA created story issues #192..#196
- SA posted all 5 parts (STRIDE, performance, ADR, etc.)

---

## Troubleshooting

### VG duplicates

If VG ever posts twice:

- Check idempotency markers (“VG Analysis - Part 1/7”) and concurrency settings.
- Verify the epic didn’t get edited/relabeled in a way that bypasses the guard.

### BA/SA didn’t run

Historically caused by bot-applied label events not producing a new run.

Current design should avoid this. If it happens:

- Check that VG approval condition was met.
- Inspect the Actions run and ensure BA/SA job conditions evaluated true.

### Testing/Deployment didn’t trigger

- Confirm you closed user stories as a human.
- Confirm the “last story closed” condition is satisfied.
- Inspect job outputs from Coding and ensure they flow into Testing/Deployment.

---

## Future Enhancements

- Ensure `sa-complete` is always applied when SA finishes (completion signaling).
- Add a “dry-run / simulate” label for analysis-only runs.
- Add metrics: time-to-branch, time-to-VG, time-to-stories, time-to-first-PR.
- Harden rate limiting/backoff around GitHub API calls.
- Add explicit governance policy for fail-open vs fail-closed behavior.

---


## Change Log

- **v2.1 (2026-01-21)**: Autonomous agent code/test/deploy generation enabled.
  - Code Agent now generates, commits, and PRs code using LLMs (Claude 4.5, GPT-5.2).
  - Coding standards strictly enforced in LLM prompts.
  - CI/CD and human review required for all PRs.
  - Test/Deploy Agent automation planned.
- **v2.0 (2026-01-20)**: Previous design.
  - Shipped via PRs #186, #188, #190.
  - VG posts directly on epic (no separate VG review issue).
  - Branch creation occurs during triage.
  - BA creates 5 story issues.
  - Reliability improvements: concurrency + idempotency; chaining avoids bot-label trigger gaps.
